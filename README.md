[![Open Source](https://img.shields.io/badge/Open%20Source-Yes-green.svg?style=flat-square)](https://github.com/hwchase17/langchain)

# ollama-colab
Serve Ollama LLMs on Google Colab (free plan) using Ngrok

If you're trying to develop a project with LangChain or similar frameworks and need access to LLM APIs, you might find yourself quickly exhausting your trial credits on platforms like OpenAI, Llama-API, or Anthropic Claude. When those credits run out, you may need to serve the APIs locally. However, if you don't have enough local resources to do so, you're in a bit of a bind. :D